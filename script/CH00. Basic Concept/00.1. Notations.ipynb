{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH00.1. **Notations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Standard Notations for Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 특징(Feature ; `input`)** : \n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, m $ : 데이터셋 샘플 개수(record size ; sample size)\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, n_{x} = n^{[0]} $ : 특징 개수\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{x}\\times{}1}{\\textbf{x}^{(i)}} = \\begin{bmatrix} x^{(i)}_{1} \\\\ x^{(i)}_{2} \\\\ \\vdots{} \\\\ x^{(i)}_{n_{x}} \\end{bmatrix} $ : $ \\, i $ 번 째 입력 데이터(벡터)\n",
    "#### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{x}\\times{}m}{X} = \\begin{bmatrix} x^{(1)}_{1} & x^{(2)}_{1} & \\cdots{} & x^{(m)}_{1} \\\\ x^{(1)}_{2} & x^{(2)}_{2} & \\cdots{} & x^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ x^{(1)}_{n_{x}} & x^{(2)}_{n_{x}} & \\cdots{} & x^{(m)}_{n_{x}} \\end{bmatrix} $ : 입력 데이터셋(행렬)\n",
    "#### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{x}^{(1)}&\\textbf{x}^{(2)}&\\cdots{}&\\textbf{x}^{(m)} \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) (분류에서의) 타겟(Target ; `input`)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, n_{y} = n^{[L]} $ : 타겟 범주(target class) 개수\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{y}\\times{}1}{\\textbf{y}^{(i)}} = \\begin{bmatrix} y^{(i)}_{1} \\\\ y^{(i)}_{2} \\\\ \\vdots{} \\\\ y^{(i)}_{n_{y}} \\end{bmatrix} $ : $ \\, i $ 번 째 타겟 범주 데이터(벡터)\n",
    "#### $ \\hspace{0.45cm} \\text{where } \\; y_{k} \\in{} \\{ 0, 1 \\} $\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{y}\\times{}m}{Y} = \\begin{bmatrix} y^{(1)}_{1} & y^{(2)}_{1} & \\cdots{} & y^{(m)}_{1} \\\\ y^{(1)}_{2} & y^{(2)}_{2} & \\cdots{} & y^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ y^{(1)}_{n_{y}} & y^{(2)}_{n_{y}} & \\cdots{} & y^{(m)}_{n_{y}} \\end{bmatrix} $ : 타겟 데이터셋(행렬) \n",
    "#### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{y}^{(1)}&\\textbf{y}^{(2)}&\\cdots{}&\\textbf{y}^{(m)}\\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 이진 분류의 경우 $ \\, n_{y} = 1 $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 회귀에서의 개별 타겟 데이터는 실수 스칼라로 정의됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 네트워크(Network)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, L $ : 네트워크의 레이어 개수\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, n_{h}^{[l]} = n^{[l]} $ : $ \\, l $ 번째 층(layer)의 은닉 노드(hidden node) 개수\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{l}\\times{}n_{h}^{l-1}}{W^{[l]}} $ : $ \\, l $ 번 째 층의 가중치(weight) 행렬 (`parameter`)\n",
    "#### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{l}\\times{}m}{B^{[l]}} $ : $ \\, l $ 번 째 층의 편향(bias) 행렬 (`parameter`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 실제 파이썬에서는 브로드캐스팅(Broadcasting)을 이용하기 때문에 편향 행렬을 스칼라로 변환하여 정의함\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} B^{[l]} \\approx{} b^{[l]} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 순방향 전파(Feed-foward propagation)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, \\underset{n_{h}^{l}\\times{}1}{\\textbf{z}^{[l](i)}} = W^{[l]}\\textbf{x}^{(i)} + \\textbf{b}^{[l](i)} $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 선형 변환 출력 벡터\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{h}^{l}\\times{}m}{Z^{[l]}} = W^{[l]}X + b^{[l]} $ : $ \\, l $ 번 째 선형 변환 출력 행렬\n",
    "#### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{z}^{[l](1)}&\\textbf{z}^{[l](2)}&\\cdots{}&\\textbf{z}^{[l](m)}\\end{bmatrix} $\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{l}\\times{}1}{\\textbf{a}^{[l](i)}} = h(\\textbf{z}^{[l](i)})$ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력 벡터\n",
    "#### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{l}\\times{}m}{A^{[l]}} = h(Z^{[l]})$ : $ \\, l $ 번 째 층의 활성화 변환 출력 행렬\n",
    "#### $ \\hspace{0.15cm} $ ⑤ $ \\, \\underset{n_{y}\\times{}m}{\\hat{\\textbf{y}}^{(i)}} = \\textbf{a}^{[L](i)} $ : $ \\, L $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력 벡터\n",
    "#### $ \\hspace{0.15cm} $ ⑥ $ \\, \\underset{n_{y}\\times{}m}{\\hat{Y}} = A^{[L]} $ : $ \\, L $ 번 째 층의 활성화 변환 출력 행렬(예측 행렬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 역방향 전파(Backward propagation)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{\\ell{}^{(i)}} $ : $ \\, i $ 번 째 손실 함수(Loss Function)\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, \\underset{1\\times{}m}{L} = \\begin{bmatrix} \\ell{}^{(1)} & \\ell{}^{(2)} & \\cdots{} & \\ell{}^{(m)} \\end{bmatrix} $ : 손실 함수\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, J = \\frac{1}{m} \\times{} \\displaystyle\\sum^{m}_{i=1} \\ell{}^{(i)} $ : 비용 함수(Cost function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
