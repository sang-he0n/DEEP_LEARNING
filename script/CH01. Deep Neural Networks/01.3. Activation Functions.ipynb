{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01.3. **Activation Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Activation Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 신경망의 뉴런이 입력 신호의 가중합을 특정 규칙에 따라 변환하여 출력 신호를 생성하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 역할** : 비선형성 도입을 통해 복잡한 패턴을 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 종류** :\n",
    "##### $ \\hspace{0.15cm} $ ① Sigmoid\n",
    "##### $ \\hspace{0.15cm} $ ② Hyperbolic Tangent\n",
    "##### $ \\hspace{0.15cm} $ ③ Softmax\n",
    "##### $ \\hspace{0.15cm} $ ④ Rectified Linear Unit(RELU)\n",
    "##### $ \\hspace{0.15cm} $ ⑤ Leaky Rectified Linear Unit(Leaky RELU)\n",
    "##### $ \\hspace{0.15cm} $ ⑥ Exponential Linear Unit(ELU)\n",
    "##### $ \\hspace{0.15cm} $ ⑦ Swish\n",
    "##### $ \\hspace{0.45cm} \\cdots{} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Sigmoid**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 출력값을 $ \\, 0, \\, 1 \\, $ 사이의 값으로 변환하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\sigma{}(z) = \\frac{1}{1+e^{-z}} \\;\\; \\text{ where } z \\in{} \\mathbb{R}^{1} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\frac{e^{-z}}{(1+e^{-z})^{2}} \\;\\; $ ($ \\because{} \\, $ 분수함수 미분)\n",
    "##### $ \\hspace{2.42cm} = \\frac{1}{(1+e^{-z})} \\frac{e^{-z}}{(1+e^{-z})} = \\frac{1}{(1+e^{-z})} (1-\\frac{1}{(1+e^{-z})}) $\n",
    "##### $ \\hspace{2.42cm} = h(z) (1-h(z)) $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (1).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① S자 형태의 곡선 형태임\n",
    "##### $ \\hspace{0.15cm} $ ② 입력값이 매우 크거나 작을 때 함수의 출력이 $ \\, 0 $ 또는 $ \\, 1 $ 에 가까워짐 (포화 현상;saturation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력 범위가 $ \\, 0 $ 에서 $ \\, 1 $ 사이기에 확률적 해석이 가능함\n",
    "##### $ \\hspace{0.15cm} $ ② 모든 구간에서 연속이며, 미분이 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 입력값이 매우 크거나 작을 경우 도함수 값이 $ \\, 0 $ 에 가까워져, 깊은 신경망 학습 시 기울기 소실 문제가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 기울기 소실(gradient vanishing) : 입력값이 너무 크거나 작으면 도함수 값이 $ \\, 0 $ 에 가까워져 파라미터 업데이트가 제대로 되지 않는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $ \\hspace{0.15cm} $ ② 평균 출력이 편향($ \\, 0 $ 이 아니라 양수로 치우쳐짐)되어 있어, 가중치 업데이트 시 비대칭적 문제를 야기할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`) 비대칭출력의 문제점** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Hyperbolic Tangent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 출력값을 $ \\, -1, \\, 1 \\, $ 사이의 값으로 변환하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\text{tanh}(z) = \\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\frac{(e^{z}-e^{-z})^{'}(e^{z}+e^{-z})-(e^{z}-e^{-z})(e^{z}+e^{-z})^{'}}{(e^{z}+e^{-z})^{2}} $\n",
    "##### $ \\hspace{2.42cm} = \\frac{(e^{z}+e^{-z})(e^{z}+e^{-z})-(e^{z}-e^{-z})(e^{z}-e^{-z})}{(e^{z}+e^{-z})^{2}} $\n",
    "##### $ \\hspace{2.42cm} = \\frac{4}{(e^{z}+e^{-z})^{2}} $\n",
    "##### $ \\hspace{2.42cm} = \\frac{4}{4\\text{cosh}^{2}(z)} \\;\\; $ ($ \\because{} \\, \\text{cosh}(z) = \\frac{e^{z}+e^{-z}}{2} $)\n",
    "##### $ \\hspace{2.42cm} = $ **[LATEX]**\n",
    "##### $ \\hspace{2.42cm} = 1 - h(z)^{2} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (2).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 입력 데이터의 분포가 대칭적이라면 출력값의 평균이 $ \\, 0 $ 임(그렇지 않다면 $ \\, 0 $ 에 가까움)\n",
    "##### $ \\hspace{0.15cm} $ ② 입력값이 매우 크거나 작을 때 함수의 출력이 $ \\, -1 $ 또는 $ \\, 1 $ 에 가까워짐 (포화 현상;saturation)\n",
    "##### $ \\hspace{0.15cm} $ ③ 기함수(odd function;$ \\, \\text{tanh}(z) = -\\text{tanh}(-z) $)이기에 원점에 대칭임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력이 $ \\, 0 $ 을 중심으로 분포하므로 학습 시 기울기 방향이 균형 있게 전달됨\n",
    "##### $ \\hspace{0.15cm} $ ② (시그모이드에 비해) 기울기 소실 문제가 어느정도 완화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 입력값이 매우 크거나 작을 경우 기울기 소실 문제가 여전히 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Softmax**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 각 클래스(범주)의 입력 값을 확률로 변환하여, 전체 합이 $ \\, 1 $이 되도록 정규화하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z_{i}) = \\frac{e^{z_{i}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z_{i}) = \\frac{(\\sum^{n_{y}}_{k=1}e^{z_{k}})-e^{z_{i}}(\\sum^{n_{y}}_{k=1}e^{z_{k}})^{'}}{(\\sum^{n_{y}}_{k=1}e^{z_{k}})^{2}} $\n",
    "##### $ \\hspace{2.475cm} = \\frac{e^{z_{i}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}(\\delta{}_{ik}-\\frac{e^{z_{k}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}) = \\begin{cases} \\frac{e^{z_{i}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}(1-\\frac{e^{z_{i}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}) \\;\\; \\text{ if } \\, i = k \\\\ -\\frac{e^{z_{i}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}\\frac{e^{z_{k}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}} \\;\\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, i \\neq{} k \\end{cases} $\n",
    "##### $ \\hspace{2.475cm} = \\begin{cases} h(z_{i})(1-h(z_{i})) \\;\\; \\text{ if } \\, i = k \\\\ -h(z_{i})h(z_{k}) \\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, i \\neq{} k \\end{cases} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (3).png\" width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 도함수의 경우 **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 각 클래스의 활성화 값은 $ \\, 0 $ 과 $ \\, 1 $ 사이이며 전체 합은 $ \\, 1 $ 이 됨 \n",
    "##### $ \\hspace{0.15cm} $ ② 하나의 클래스 활성화 값이 변하면 다른 출력 값에도 영향을 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력값의 총합이 $ \\, 1 $ 이 되어(확률 분포를 생성하므로), 산출값에 대해 확률적 해석 가능\n",
    "##### $ \\hspace{0.15cm} $ ② 모든 구간에서 연속이며, 미분이 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 입력 스케일에 민감하여, 적절한 안정화 기법이 필요함\n",
    "##### $ \\hspace{0.15cm} $ ② 클래스 수가 많을 경우 연산 비용 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Rectified Linear Unit(RELU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 입력값을 $ \\, 0 $ 보다 크면 그대로 출력하고, $ \\, 0 $ 이하이면 $ \\, 0 $ 을 출력하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\text{max}(0,\\, z) $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\begin{cases} 1, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{ if } \\, z > 0 \\\\ \\text{not define}. \\;\\; \\text{if } \\, z = 0 \\\\ 0, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{ if } \\, z < 0 \\end{cases} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (4).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 비선형 함수지만, 부분적으로 선형 구간이 존재\n",
    "##### $ \\hspace{0.15cm} $ ② 입력 $ \\, 0 $ 에서 미분이 정의되지 않음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 계산이 매우 간단하여 연산 효율성이 높음\n",
    "##### $ \\hspace{0.15cm} $ ② 양의 입력에 대해 일정한 기울기를 제공하여, 역전파 시 기울기 소실 문제를 완화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 음수 영역에서 미분값이 $ \\, 0 $ 이므로, 많은 뉴런이 비활성화되어 학습이 멈출 위험 존재 (dying ReLU)\n",
    "##### $ \\hspace{0.15cm} $ ② 출력이 $ \\, 0 $ 이상으로 치우쳐 있어, 출력 분포가 비대칭적임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Leaky Rectified Linear Unit(Leaky RELU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 입력이 음수일 때도 작은 기울기를 갖는 RELU의 변형 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\text{max}(\\alpha{} \\cdot{} z,\\, z) \\;\\; \\text{ where } \\, 0 \\leq{} \\alpha{} \\leq{} 1 $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\begin{cases} 1, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{ if } \\, z > 0 \\\\ \\text{not define}. \\;\\; \\text{if } \\, z = 0 \\\\ \\alpha{}, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{ if } \\, z < 0 \\end{cases} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (5).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 양수 구간에서는 ReLU와 동일하게 작동하고, 음수 구간에서는 작은 기울기를 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 음수 영역에서도 미세한 기울기를 제공하여 뉴런이 완전히 죽는 문제를 완화\n",
    "##### $ \\hspace{0.15cm} $ ② (ReLU에 비해) 학습이 안정적으로 진행될 가능성이 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 음수 영역의 기울기 $ \\, \\alpha{} $ 는 하이퍼 파라미터이기에 경험적으로 설정됨\n",
    "##### $ \\hspace{0.15cm} $ ② (ReLU에 비해) 약간의 계산 비용 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Exponential Linear Unit(ELU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 기존 RELU 함수의 음수 영역에서도 지수 함수를 사용하여 부드러운 출력\n",
    "#### $ \\hspace{0.15cm} $ ① 함수 $ \\, h(z) = \\begin{cases} z, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; z > 0 \\\\ \\alpha{} \\cdot{} ( e^{z} - 1), \\;\\; z \\leq{} 0 \\end{cases} $\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\begin{cases} 1, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; z > 0 \\\\ h(z) + \\alpha{}, \\;\\; z \\leq{} 0 \\end{cases} $ \n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (6).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 전체 활성화 분포의 평균을 $ \\, 0 $ 에 가깝게 만들 수 있음\n",
    "##### $ \\hspace{0.15cm} $ ② **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 음수 영역에서도 미분값이 $ \\, 0 $ 이 아니므로 기울기 소실 문제를 줄임\n",
    "##### $ \\hspace{0.15cm} $ ② 평균 활성화를 $ \\, 0 $ 에 가깝게 만들어 학습 속도를 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① **[CONTENTS]**\n",
    "##### $ \\hspace{0.15cm} $ ② **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Swish**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 시그모이드 함수와 입력값을 곱한 값을 출력하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = z \\cdot{} \\sigma{}(\\beta{} \\cdot{} z) = z \\cdot{} \\frac{1}{1+e^{-\\beta{}\\cdot{}z}} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = f(z) + \\sigma{}(\\beta{} \\cdot{} z)(1 - \\beta{} \\cdot{} h(z)) = \\sigma{}(\\beta{} \\cdot{} z) + \\beta{} \\cdot{} z \\cdot{} \\sigma{}(\\beta{}\\cdot{}z)(1 - \\sigma{}(\\beta{} \\cdot{} z)) $\n",
    "##### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (7).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 단조 증가 함수가 아니므로, 특정 영역에서는 미세한 하강을 보임 (non-monotonic)\n",
    "##### $ \\hspace{0.15cm} $ ② 음수 및 양수 모두 출력할 수 있어 출력값이 $ \\, 0 $ 중심에 가까운 분포를 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 부드러운 비선형성 덕분에 역전파 시 기울기 흐름이 원활하여, 학습이 개선됨\n",
    "##### $ \\hspace{0.15cm} $ ② 죽은 뉴런 문제 없이 음수 영역에서도 정보를 전달함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 특정 영역에서 미세한 하강을 보이므로 모든 문제에 대해 항상 안정적인 학습을 보장하지 않음\n",
    "##### $ \\hspace{0.15cm} $ ② (ReLU에 비해) 계산 비용이 더 높음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
