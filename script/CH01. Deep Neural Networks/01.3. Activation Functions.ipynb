{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01.3. **Activation Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **활성화 함수(Activation Function)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 신경망의 노드 별 선형결합 값($ z $)을 특정 규칙에 따라 변환하여 출력하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 목적** : 비선형성 도입을 통해 복잡한 패턴을 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`WHY?`)** 비선형성이 도입되지 않는다면 레이어를 아무리 깊게 설정해도 모든 레이어별로 선형결합되어 단층 네트워크가 됨\n",
    "##### $ \\hspace{0.15cm} \\Rightarrow{} W^{[2]}(W^{[1]}X) = W^{[*]} \\cdot{} X $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 종류** :\n",
    "##### $ \\hspace{0.15cm} $ ① 시그모이드(Sigmoid)\n",
    "##### $ \\hspace{0.15cm} $ ② 하이퍼볼릭 탄젠트(Hyperbolic Tangent)\n",
    "##### $ \\hspace{0.15cm} $ ③ 소프트맥스(Softmax)\n",
    "##### $ \\hspace{0.15cm} $ ④ 렐루(Rectified Linear Unit;ReLU)\n",
    "##### $ \\hspace{0.15cm} $ ⑤ 리키 렐루(Leaky Rectified Linear Unit;Leaky ReLU)\n",
    "##### $ \\hspace{0.15cm} $ ⑥ 엘루(Exponential Linear Unit;ELU)\n",
    "##### $ \\hspace{0.15cm} $ ⑦ 스위시(swish;SiLu)\n",
    "##### $ \\hspace{0.45cm} \\cdots{} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **시그모이드(Sigmoid)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 출력(활성화)값을 $ \\, 0, \\, 1 \\, $ 사이의 값으로 변환하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\sigma{}(z) = \\frac{e^{z}}{1+e^{z}}=\\frac{1}{1+e^{-z}} \\;\\; \\text{ where } \\, z \\in{} \\mathbb{R}^{1} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\frac{e^{-z}}{(1+e^{-z})^{2}} \\;\\; $ ($ \\because{} \\, $ 분수함수 미분)\n",
    "##### $ \\hspace{2.42cm} = \\frac{1}{(1+e^{-z})} \\frac{e^{-z}}{(1+e^{-z})} = \\frac{1}{(1+e^{-z})} (1-\\frac{1}{(1+e^{-z})}) $\n",
    "##### $ \\hspace{2.42cm} = h(z) (1-h(z)) $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (1).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 시그모이드는 로짓공간에 있는 값($ z $)을 베르누이 분포를 따르는 확률변수($ a $)의 확률 파라미터로 매핑하기 위한 함수임\n",
    "##### $ \\Rightarrow{} P(a=1|x) = \\sigma{}(z) \\;\\; \\text{ where } \\, \\sigma{} : \\mathbb{R} \\rightarrow{} ( 0, 1 ) \\, \\text{ and } \\, a \\sim{} \\text{Bernoulli}(p=\\sigma{}(z)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① S자 형태의 곡선 형태임\n",
    "##### $ \\hspace{0.15cm} $ ② 입력값이 매우 크거나 작을 때 함수의 출력이 $ \\, 0 $ 또는 $ \\, 1 $ 에 가까워짐 (포화 현상;saturation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력 범위가 $ \\, 0 $ 에서 $ \\, 1 $ 사이기에 확률적 해석이 가능함\n",
    "##### $ \\hspace{0.15cm} $ ② 모든 구간에서 연속이며, 미분이 가능하기에 그래디언트가 급변하지 않음 (학습이 안정적임)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 입력값이 매우 크거나 작을 경우 도함수 값이 $ \\, 0 $ 에 가까워져, 깊은 신경망 학습 시 기울기 소실 문제가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 기울기 소실(gradient vanishing) : 입력값이 너무 크거나 작으면 도함수 값이 $ \\, 0 $ 에 가까워져 파라미터 업데이트가 제대로 되지 않는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $ \\hspace{0.15cm} $ ② 평균 출력이 편향($ \\, 0 $ 이 아니라 양수로 치우쳐짐)되어 있어, 가중치 업데이트 시 비대칭적 문제를 야기할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`) 비대칭출력의 문제점** : \n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 가중치 업데이트 시 그래디언트가 특정 방향으로만 누적되는 문제가 발생\n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 그래디언트가 특정 방향으로만 불균형하게 이루어져 학습 효율을 떨어지고 (손실함수의 최적해) 수렴을 느리게 할 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **하이퍼볼릭 탄젠트(Hyperbolic Tangent)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 출력값을 $ \\, -1, \\, 1 \\, $ 사이의 값으로 변환하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\text{tanh}(z) = \\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\frac{(e^{z}-e^{-z})^{'}(e^{z}+e^{-z})-(e^{z}-e^{-z})(e^{z}+e^{-z})^{'}}{(e^{z}+e^{-z})^{2}} $\n",
    "##### $ \\hspace{2.42cm} = \\frac{(e^{z}+e^{-z})(e^{z}+e^{-z})-(e^{z}-e^{-z})(e^{z}-e^{-z})}{(e^{z}+e^{-z})^{2}} = \\frac{(e^{z}+e^{-z})^{2}-(e^{z}-e^{-z})^{2}}{(e^{z}+e^{-z})^{2}} $\n",
    "##### $ \\hspace{2.42cm} = \\frac{4}{(e^{z}+e^{-z})^{2}} $\n",
    "##### $ \\hspace{2.42cm} = \\frac{4}{4\\text{cosh}^{2}(z)} \\;\\; $ ($ \\because{} \\, \\text{cosh}(z) = \\frac{e^{z}+e^{-z}}{2} $)\n",
    "##### $ \\hspace{2.42cm} = $ **[LATEX]**\n",
    "##### $ \\hspace{2.42cm} = 1 - h(z)^{2} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (2).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 입력 데이터의 분포가 대칭적이라면 출력값의 평균이 $ \\, 0 $ 임(그렇지 않다면 $ \\, 0 $ 에 가까움)\n",
    "##### $ \\hspace{0.15cm} $ ② 입력값이 매우 크거나 작을 때 함수의 출력이 $ \\, -1 \\, $ 또는 $ \\, 1 $ 에 가까워짐\n",
    "##### $ \\hspace{0.15cm} $ ③ 기함수(odd function)임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`) 기함수(odd function)** : 원점에 대칭인 함수 \n",
    "##### $ \\hspace{0.15cm} \\Rightarrow{} \\text{tanh}(z) = -\\text{tanh}(-z) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력이 $ \\, 0 $ 을 중심으로 분포하므로 학습 시 기울기 방향이 균형 있게 전달됨\n",
    "##### $ \\hspace{0.15cm} $ ② 모든 구간에서 연속이며, 미분이 가능하기에 그래디언트가 급변하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① (시그모이드에 비해) 기울기 소실 문제가 어느정도 완화하나, 입력값이 클 경우 여전히 발생 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **소프트맥스(Softmax)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 각 클래스(범주)의 입력 값을 확률로 변환하여, 전체 합이 $ \\, 1 $이 되도록 정규화하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z_{c}) = \\frac{e^{z_{c}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z_{c}) = \\frac{(\\sum^{n_{y}}_{k=1}e^{z_{k}})-e^{z_{c}}(\\sum^{n_{y}}_{k=1}e^{z_{k}})^{'}}{(\\sum^{n_{y}}_{k=1}e^{z_{k}})^{2}} $\n",
    "##### $ \\hspace{2.475cm} = \\frac{e^{z_{c}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}(\\delta{}_{ik}-\\frac{e^{z_{k}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}) = \\begin{cases} \\frac{e^{z_{c}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}(1-\\frac{e^{z_{c}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}) \\;\\; \\text{ if } \\, i = k \\\\ -\\frac{e^{z_{c}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}}\\frac{e^{z_{k}}}{\\sum^{n_{y}}_{k=1}e^{z_{k}}} \\;\\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, i \\neq{} k \\end{cases} $\n",
    "##### $ \\hspace{2.475cm} = \\begin{cases} h(z_{c})(1-h(z_{c})) \\;\\; \\text{ if } \\, i = k \\\\ -h(z_{c})h(z_{k}) \\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, i \\neq{} k \\end{cases} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (3).png\" width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 소프트맥스는 다변수 함수이기 때문에 도함수의 경우 자코비안 형태로 표현되나, **[LATEX]** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 각 클래스의 출력 값은 $ \\, 0 $ 과 $ \\, 1 $ 사이이며 전체 합은 $ \\, 1 $ 이 됨 \n",
    "##### $ \\hspace{0.15cm} $ ② 하나의 클래스 출력 값이 변하면 다른 출력 값에도 영향을 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력값의 총합이 $ \\, 1 $ 이 되어(확률 분포를 생성하므로) 확률적 해석 가능\n",
    "##### $ \\hspace{0.15cm} $ ② 모든 구간에서 연속이며, 미분이 가능하기에 그래디언트가 급변하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 지수 함수를 사용하기 때문에 입력 스케일에 민감함\n",
    "##### $ \\hspace{0.15cm} $ ② 클래스 수가 많을 경우 연산 비용 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **렐루(Rectified Linear Unit;ReLU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 입력값을 $ \\, 0 $ 보다 크면 그대로 출력하고, $ \\, 0 $ 이하이면 $ \\, 0 $ 을 출력하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\text{max}(0,\\, z) $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\begin{cases} 1, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, z > 0 \\\\ \\text{not define}, \\;\\; \\text{if } \\, z = 0 \\\\ 0, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, z < 0 \\end{cases} $\n",
    "##### $ \\hspace{2.45cm} \\approx{} \\begin{cases} 1, \\;\\; \\text{ if } \\, z \\geq{} 0 \\\\ 0, \\;\\; \\text{ if } \\, z < 0 \\end{cases} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (4).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 비선형 함수지만, 부분적으로 선형 구간이 존재\n",
    "##### $ \\hspace{0.15cm} $ ② 입력 $ \\, 0 $ 에서 미분이 정의되지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 계산이 매우 간단하여 연산 효율성이 높음\n",
    "##### $ \\hspace{0.15cm} $ ② 양의 입력($ z > 0 $)에 대해 일정한 기울기를 제공하여, 역전파 시 기울기 소실 문제를 어느정도 완화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** : \n",
    "##### $ \\hspace{0.15cm} $ ① 음수 영역에서 미분값이 $ \\, 0 $ 이므로, 많은 뉴런이 비활성화되어 학습이 멈출 위험 존재 (dying ReLU)\n",
    "##### $ \\hspace{0.15cm} $ ② 평균 출력이 편향되어 있어, 가중치 업데이트 시 비대칭적 문제를 야기할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **리키 렐루(Leaky Rectified Linear Unit;Leaky ReLU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 입력이 음수일 때도 작은 기울기를 갖는 RELU의 변형 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = \\text{max}(\\alpha{} \\cdot{} z,\\, z) \\;\\; \\text{ where } \\, 0 \\leq{} \\alpha{} \\leq{} 1 $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = \\begin{cases} 1, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\, \\text{ if } \\, z > 0 \\\\ \\text{not define}, \\;\\; \\text{if } \\, z = 0 \\\\ \\alpha{}, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\,\\, \\text{ if } \\, z < 0 \\end{cases} $\n",
    "##### $ \\hspace{2.45cm} \\approx{} \\begin{cases} 1, \\;\\; \\text{ if } \\, z \\geq{} 0 \\\\ \\alpha{}, \\;\\, \\text{ if } \\, z < 0 \\end{cases} $\n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (5).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 양수 구간에서는 ReLU와 동일하게 작동하고, 음수 구간에서는 작은 기울기를 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 음수 영역에서도 기울기를 제공하기에 뉴런이 완전히 죽는 문제를 완화 $ \\rightarrow{} $ (ReLU에 비해) 학습이 안정적으로 진행될 가능성이 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\alpha{} $ 는 하이퍼 파라미터이기에 경험적으로 설정해야함 (일반적으로 $ \\, 0.001 \\sim{} 0.3 $)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **엘루(Exponential Linear Unit;ELU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 기존 RELU 함수의 음수 영역에서도 지수 함수를 사용하여 부드러운 출력\n",
    "#### $ \\hspace{0.15cm} $ ① 함수 $ \\, h(z) = \\begin{cases} z, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{ if } \\, z > 0 \\\\ \\alpha{} \\cdot{} ( e^{z} - 1), \\;\\; \\text{ if } \\, z \\leq{} 0 \\end{cases} $\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = $ **[LATEX]**\n",
    "#### $ \\hspace{2.4cm} = \\begin{cases} 1, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{ if } \\, z > 0 \\\\ h(z) + \\alpha{}, \\;\\; \\text{ if } \\, z \\leq{} 0 \\end{cases} $ \n",
    "#### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (6).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 전체 출력 분포의 평균을 $ \\, 0 $ 에 가깝게 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 출력이 $ \\, 0 $ 을 중심으로 분포하므로 학습 시 기울기 방향이 균형 있게 전달됨\n",
    "##### $ \\hspace{0.15cm} $ ② 음수 영역에서도 미분값이 $ \\, 0 $ 이 아니므로 기울기 소실 문제를 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\alpha{} $ 는 하이퍼 파라미터이기에 경험적으로 설정해야함\n",
    "##### $ \\hspace{0.15cm} $ ② 음수 값 계산에서 지수함수로 인한 오버헤드(overhead;계산시간이 추가로 더 걸리는 문제)가 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **스위시(swish;SiLU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 시그모이드 함수와 입력값을 곱한 값을 출력하는 함수\n",
    "##### $ \\hspace{0.15cm} $ ① 함수 : $ \\, h(z) = z \\cdot{} \\sigma{}(\\beta{} \\cdot{} z) = z \\cdot{} \\frac{1}{1+e^{-\\beta{}\\cdot{}z}} $\n",
    "##### $ \\hspace{0.15cm} $ ② 도함수 : $ \\, h'(z) = f(z) + \\sigma{}(\\beta{} \\cdot{} z)(1 - \\beta{} \\cdot{} h(z)) = \\sigma{}(\\beta{} \\cdot{} z) + \\beta{} \\cdot{} z \\cdot{} \\sigma{}(\\beta{}\\cdot{}z)(1 - \\sigma{}(\\beta{} \\cdot{} z)) $\n",
    "##### $ \\hspace{0.3cm} $ <img src=\"../../img/00.2. Activation Functions (7).png\" width=\"40%\" height=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** :\n",
    "##### $ \\hspace{0.15cm} $ ① 단조 함수가 아닌 비단조함수(non-monotonic function)임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 단조함수 : 주어진 순서를 보존하는 함수 $ \\rightarrow{} \\, f(x_{1}) < f(x_{2}) \\;\\; \\text{ if } \\, x_{1} < x_{2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $ \\hspace{0.15cm} $ ② 음수 및 양수 모두 출력할 수 있어 출력값이 $ \\, 0 \\, $ 중심에 가까운 분포를 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 모든 구간에서 연속이며, 미분이 가능하기에 그래디언트가 급변하지 않음\n",
    "##### $ \\hspace{0.15cm} $ ② 죽은 뉴런 문제 없이 음수 영역에서도 정보를 전달함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 비단조적 특징 때문에 입력이 증가하더라도 출력이 감소하는 구간이 존재해 학습이 불안정할 수 있음 \n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\beta{} $ 는 하이퍼 파라미터이기에 경험적으로 설정해야함 (일반적으로 $ \\, 1 $)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
