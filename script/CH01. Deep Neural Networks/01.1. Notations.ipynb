{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01.1. **Notations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Standard Notations for Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 특징(Feature ; `input`)** : \n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, m $ : 데이터 샘플 개수\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, n_{x} = n^{[0]} $ : 특징(변수) 개수\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{x}\\times{}1}{\\textbf{x}^{(i)}} = \\textbf{a}^{[0](i)} = \\begin{bmatrix} x^{(i)}_{1} \\\\ x^{(i)}_{2} \\\\ \\vdots{} \\\\ x^{(i)}_{n_{x}} \\end{bmatrix} $ : $ \\, i $ 번 째 입력 데이터\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{x}\\times{}m}{X} = A^{[0]} = \\begin{bmatrix} x^{(1)}_{1} & x^{(2)}_{1} & \\cdots{} & x^{(m)}_{1} \\\\ x^{(1)}_{2} & x^{(2)}_{2} & \\cdots{} & x^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ x^{(1)}_{n_{x}} & x^{(2)}_{n_{x}} & \\cdots{} & x^{(m)}_{n_{x}} \\end{bmatrix} $ : 전체 입력 데이터\n",
    "##### $ \\hspace{1.385cm} = \\begin{bmatrix} \\textbf{x}^{(1)}&\\textbf{x}^{(2)}&\\cdots{}&\\textbf{x}^{(m)} \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) (분류에서의) 타겟(Target ; `input`)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, n_{y} = n^{[L]} $ : 타겟 범주(target class) 개수\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{y}\\times{}1}{\\textbf{y}^{(i)}} = \\begin{bmatrix} y^{(i)}_{1} \\\\ y^{(i)}_{2} \\\\ \\vdots{} \\\\ y^{(i)}_{n_{y}} \\end{bmatrix} $ : $ \\, i $ 번 째 타겟 범주 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 이진 분류의 경우 $ \\, n_{y} = 1 $ 이며, 회귀에서의 개별 타겟 데이터는 스칼라로 정의됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{y}\\times{}m}{Y} = \\begin{bmatrix} y^{(1)}_{1} & y^{(2)}_{1} & \\cdots{} & y^{(m)}_{1} \\\\ y^{(1)}_{2} & y^{(2)}_{2} & \\cdots{} & y^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ y^{(1)}_{n_{y}} & y^{(2)}_{n_{y}} & \\cdots{} & y^{(m)}_{n_{y}} \\end{bmatrix} $ : 전체 타겟 범주 데이터\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{y}^{(1)}&\\textbf{y}^{(2)}&\\cdots{}&\\textbf{y}^{(m)}\\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 네트워크(Network)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, L $ : 네트워크의 레이어 개수\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, n_{h}^{[l]} = n^{[l]} $ : $ \\, l $ 번째 층(layer)의 은닉 노드(hidden node) 개수\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{[l]}\\times{}n_{h}^{[l-1]}}{W^{[l]}} $ : $ \\, l $ 번 째 층의 가중치(weight)\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{[l]}\\times{}m}{B^{[l]}} $ : $ \\, l $ 번 째 층의 편향(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 실제 컴퓨터 연산에서는 브로드캐스팅(broadcasting)을 이용하여 차원을 확장함\n",
    "##### $ \\hspace{0.15cm} \\Rightarrow{} B^{[l]} \\approx{} b^{[l]} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 순방향 전파(Feed-foward propagation)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{n_{h}^{[l]}\\times{}1}{\\textbf{z}^{[l](i)}} = W^{[l]}\\textbf{x}^{(i)} + \\textbf{b}^{[l](i)} $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 선형 변환 출력\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{h}^{[l]}\\times{}m}{Z^{[l]}} = W^{[l]}X + b^{[l]} $ : $ \\, l $ 번 째 전체 데이터의 선형 변환 출력\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{z}^{[l](1)}&\\textbf{z}^{[l](2)}&\\cdots{}&\\textbf{z}^{[l](m)}\\end{bmatrix} $\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{[l]}\\times{}1}{\\textbf{a}^{[l](i)}} = h^{[l]}(\\textbf{z}^{[l](i)})$ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{[l]}\\times{}m}{A^{[l]}} = h^{[l]}(Z^{[l]})$ : $ \\, l $ 번 째 층의 전체 데이터의 활성화 변환 출력\n",
    "##### $ \\hspace{0.15cm} $ ⑤ $ \\, \\underset{n_{y}\\times{}m}{\\hat{\\textbf{y}}^{(i)}} = \\textbf{a}^{[L](i)} $ : $ \\, L $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력\n",
    "##### $ \\hspace{0.15cm} $ ⑥ $ \\, \\underset{n_{y}\\times{}m}{\\hat{Y}} = A^{[L]} $ : $ \\, L $ 번 째 층의 전체 데이터의 활성화 변환 출력(예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 역방향 전파(Backward propagation)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{\\ell{}^{(i)}} =  \\ell{}(\\textbf{y}^{(i)},\\,\\hat{\\textbf{y}}^{(i)}) $ : $ \\, i $ 번 째 손실(loss)\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{1\\times{}m}{L} = \\begin{bmatrix} \\ell{}^{(1)} & \\ell{}^{(2)} & \\cdots{} & \\ell{}^{(m)} \\end{bmatrix} $ : 전체 데이터의 손실\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, J = J(W^{[1]},B^{[1]},\\cdots{})=\\frac{1}{m} \\times{} \\displaystyle\\sum^{m}_{i=1} \\ell{}^{(i)} $ : 비용(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
