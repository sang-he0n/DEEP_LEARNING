{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01.1. **Notations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **딥러닝 기본 표기법(Standard Notations for Deep Learning)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 특징(Feature ; `input`)** : \n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{m} $ : 데이터 샘플 개수\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{1\\times{}1}{n_{x}} $ : 특징(변수) 개수\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{x}\\times{}1}{\\textbf{x}^{(i)}} = \\begin{bmatrix} x^{(i)}_{1} \\\\ x^{(i)}_{2} \\\\ \\vdots{} \\\\ x^{(i)}_{n_{x}} \\end{bmatrix} $ : $ \\, i $ 번 째 입력 데이터 벡터\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{x}\\times{}m}{X} = \\begin{bmatrix} \\textbf{x}^{(1)}&\\textbf{x}^{(2)}&\\cdots{}&\\textbf{x}^{(m)} \\end{bmatrix} $ : 전체 입력 데이터 행렬\n",
    "##### $ \\hspace{1.385cm} = \\begin{bmatrix} x^{(1)}_{1} & x^{(2)}_{1} & \\cdots{} & x^{(m)}_{1} \\\\ x^{(1)}_{2} & x^{(2)}_{2} & \\cdots{} & x^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ x^{(1)}_{n_{x}} & x^{(2)}_{n_{x}} & \\cdots{} & x^{(m)}_{n_{x}} \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 입력 데이터를 $ \\, 0 $ 번째 층이라고 정의하여 $ \\, X = A^{[0]}, \\; $ 특징 변수 개수를 $ \\, n_{x} = n^{[0]} $ 로도 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2-1) (분류에서의) 타겟(Target ; `input`)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{n_{y}} = n^{[L]} $ : 타겟 범주(target class) 개수\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{1\\times{}1}{y^{(i)}_{*}} $ : 타겟 범주 인덱스\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{y}\\times{}1}{\\textbf{y}^{(i)}} = \\begin{bmatrix} y^{(i)}_{1} \\\\ y^{(i)}_{2} \\\\ \\vdots{} \\\\ y^{(i)}_{n_{y}} \\end{bmatrix} $ : $ \\, i $ 번 째 타겟 범주 데이터 벡터\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{y}\\times{}m}{Y} = \\begin{bmatrix} \\textbf{y}^{(1)}&\\textbf{y}^{(2)}&\\cdots{}&\\textbf{y}^{(m)}\\end{bmatrix} $ : 전체 타겟 범주 데이터 행렬\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} y^{(1)}_{1} & y^{(2)}_{1} & \\cdots{} & y^{(m)}_{1} \\\\ y^{(1)}_{2} & y^{(2)}_{2} & \\cdots{} & y^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ y^{(1)}_{n_{y}} & y^{(2)}_{n_{y}} & \\cdots{} & y^{(m)}_{n_{y}} \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 이진 분류의 경우 $ \\, n_{y} = 1 $ 임\n",
    "##### $ \\hspace{0.15cm} \\Rightarrow{} \\textbf{Y} = \\begin{bmatrix} y^{(1)}_{*} & y^{(2)}_{*} & \\cdots{} & y^{(m)}_{*} \\end{bmatrix} \\;\\; \\text{ where } \\, y^{(i)}_{*} \\in{} \\{ 0, 1 \\} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2-2) (회귀에서의) 타겟(Target ; `input`)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{n_{y}\\times{}1}{\\textbf{y}^{(i)}} = \\begin{bmatrix} y^{(1)}&y^{(2)}&\\cdots{}&y^{(m)}\\end{bmatrix} $ : $ \\, i $ 번 째 타겟 데이터 벡터\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{y}\\times{}m}{Y} = \\begin{bmatrix} \\textbf{y}^{(1)}&\\textbf{y}^{(2)}&\\cdots{}&\\textbf{y}^{(m)}\\end{bmatrix} $ : 전체 타겟 데이터 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 네트워크(Network)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{L} $ : 네트워크의 레이어 개수\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{1\\times{}1}{n_{h}^{[l]}} = n^{[l]} $ : $ \\, l $ 번 째 층(layer)의 은닉 노드(node;뉴런) 개수\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{1\\times{}n_{h}^{[l-1]}}{\\textbf{w}^{[l]}_{k}} = \\begin{bmatrix} w^{[l]}_{k,1} & w^{[l]}_{k,2} & \\cdots{} & w^{[l]}_{k,n^{[l-1]}} \\end{bmatrix} $ : $ \\, l $ 번 째 층, $ \\, k $ 번 째 노드의 가중치(weight) 벡터\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{[l]}\\times{}n_{h}^{[l-1]}}{W^{[l]}} = \\begin{bmatrix} \\textbf{w}^{[l]}_{1} \\\\ \\textbf{w}^{[l]}_{2} \\\\ \\vdots{} \\\\ \\textbf{w}^{[l]}_{n^{[l]}_{h}} \\end{bmatrix} $ : $ \\, l $ 번 째 층의 가중치 행렬\n",
    "##### $ \\hspace{1.8cm} = \\begin{bmatrix} w^{[l]}_{1,1} & w^{[l]}_{1,2} & \\cdots{} & w^{[l]}_{1,n^{[l-1]}} \\\\ w^{[l]}_{2,1} & w^{[l]}_{2,2} & \\cdots{} & w^{[l]}_{2,n^{[l-1]}}  \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ w^{[l]}_{n^{[l]}_{h},1} & w^{[l]}_{n^{[l]}_{h},2} & \\cdots{} & w^{[l]}_{n^{[l]}_{h},n^{[l-1]}}  \\end{bmatrix} $\n",
    "##### $ \\hspace{0.15cm} $ ⑤ $ \\, \\underset{1\\times{}1}{b^{[l]}_{k}} $ : $ \\, l $ 번 째 층, $ \\, k $ 번 째 노드의 편향(bias)\n",
    "##### $ \\hspace{0.15cm} $ ⑥ $ \\, \\underset{n_{h}^{[l]}\\times{}m}{B^{[l]}} = \\begin{bmatrix} b^{[l]}_{1} & b^{[l]}_{1} & \\cdots{} & b^{[l]}_{1} \\\\ b^{[l]}_{2} & b^{[l]}_{2} & \\cdots{} & b^{[l]}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ b^{[l]}_{n^{[l]}_{h}} & b^{[l]}_{n^{[l]}_{h}} & \\cdots{} & b^{[l]}_{n^{[l]}_{h}} \\end{bmatrix} $ : $ \\, l $ 번 째 층의 편향(bias) 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 실제 컴퓨터 연산에서는 브로드캐스팅(broadcasting)을 이용하여 차원을 확장함\n",
    "##### $ \\hspace{0.15cm} \\Rightarrow{} B^{[l]} \\approx{} \\underset{1\\times{}1}{\\textbf{b}^{[l]}} = \\begin{bmatrix} b^{[l]}_{1} \\\\ b^{[l]}_{2} \\\\ \\vdots{} \\\\ b^{[l]}_{n^{[l]}_{h}} \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 순방향 전파(Foward propagation)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{z^{[l](i)}_{k}} = \\displaystyle\\sum^{n^{[l-1]}}_{p=1} w^{[l]}_{k,p}a^{[l-1](i)}_{p} + b^{[l]}_{k} $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터, $ \\, k $ 번 째 노드의 선형 변환 출력\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{h}^{[l]}\\times{}1}{\\textbf{z}^{[l](i)}} = W^{[l]}\\textbf{a}^{[l-1](i)} + \\textbf{b}^{[l]} $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 선형 변환 출력 벡터\n",
    "##### $ \\hspace{1.4cm} = \\begin{bmatrix} z^{[l](i)}_{1} \\\\ z^{[l](i)}_{2} \\\\ \\vdots{} \\\\ z^{[l](i)}_{n^{[l]}_{h}} \\end{bmatrix} $\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{[l]}\\times{}m}{Z^{[l]}} = W^{[l]}X + b^{[l]} $ : $ \\, l $ 번 째 층의 전체 데이터 선형 변환 출력 행렬\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{z}^{[l](1)} & \\textbf{z}^{[l](2)} & \\cdots{} & \\textbf{z}^{[l](m)} \\end{bmatrix} $\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} z^{[l](1)}_{1} & z^{[l](2)}_{1} & \\cdots{} & z^{[l](m)}_{1} \\\\ z^{[l](1)}_{2} & z^{[l](2)}_{2} & \\cdots{} & z^{[l](m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ z^{[l](1)}_{n^{[l]}_{h}} & z^{[l](2)}_{n^{[l]}_{h}} & \\cdots{} & z^{[l](m)}_{n^{[l]}_{h}} \\end{bmatrix} $\n",
    "##### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{}{a^{[l](i)}_{k}} = h^{[l]}(z^{[l](i)}_{k}) $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터, $ \\, k $ 번 째 노드의 활성화 출력\n",
    "##### $ \\hspace{0.15cm} $ ⑤ $ \\, \\underset{n_{h}^{[l]}\\times{}1}{\\textbf{a}^{[l](i)}} = h^{[l]}(\\textbf{z}^{[l](i)})$ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력 벡터\n",
    "##### $ \\hspace{1.4cm} = \\begin{bmatrix} a^{[l](i)}_{1} \\\\ a^{[l](i)}_{2} \\\\ \\vdots{} \\\\ a^{[l](i)}_{n^{[l]}_{h}} \\end{bmatrix} $\n",
    "##### $ \\hspace{0.15cm} $ ⑥ $ \\, \\underset{n_{h}^{[l]}\\times{}m}{A^{[l]}} = h^{[l]}(Z^{[l]})$ : $ \\, l $ 번 째 층의 전체 데이터 활성화 변환 출력 행렬\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{a}^{[l](1)} & \\textbf{a}^{[l](2)} & \\cdots{} & \\textbf{a}^{[l](m)} \\end{bmatrix} $\n",
    "##### $ \\hspace{1.375cm} = \\begin{bmatrix} a^{[l](1)}_{1} & a^{[l](2)}_{1} & \\cdots{} & a^{[l](m)}_{1} \\\\ a^{[l](1)}_{2} & a^{[l](2)}_{2} & \\cdots{} & a^{[l](m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ a^{[l](1)}_{n^{[l]}_{h}} & a^{[l](2)}_{n^{[l]}_{h}} & \\cdots{} & a^{[l](m)}_{n^{[l]}_{h}} \\end{bmatrix} $\n",
    "##### $ \\hspace{0.15cm} $ ⑦ $ \\, \\underset{n_{y}\\times{}m}{\\hat{\\textbf{y}}^{(i)}} = \\textbf{a}^{[L](i)} $ : $ \\, L $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력(예측) 벡터\n",
    "##### $ \\hspace{0.15cm} $ ⑧ $ \\, \\underset{n_{y}\\times{}m}{\\hat{Y}} = A^{[L]} $ : $ \\, L $ 번 째 층의 전체 데이터 활성화 변환 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 역방향 전파(Backward propagation)** :\n",
    "##### $ \\hspace{0.15cm} $ ① $ \\, \\underset{1\\times{}1}{\\ell{}(\\textbf{y}^{(i)},\\,\\hat{\\textbf{y}}^{(i)})} = \\ell{}^{(i)} $ : $ \\, i $ 번 째 데이터의 손실(loss)\n",
    "##### $ \\hspace{0.15cm} $ ② $ \\, \\underset{1\\times{}m}{L} = \\begin{bmatrix} \\ell{}^{(1)} & \\ell{}^{(2)} & \\cdots{} & \\ell{}^{(m)} \\end{bmatrix} $ : 전체 데이터의 손실\n",
    "##### $ \\hspace{0.15cm} $ ③ $ \\, \\displaystyle\\underset{1\\times{}1}{J} = J(W^{[1]},B^{[1]},\\cdots{}) = \\frac{1}{m} \\sum^{m}_{i=1} \\ell{}^{(i)} $ : 비용(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
