{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01.4. **Loss Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **손실 함수(Loss Function)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 모델의 예측값과 실제 정답 간의 차이를 측정 및 정량화한 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 종류** :\n",
    "##### $ \\hspace{0.15cm} $ ① 회귀(regression) : MAE, MSE, $ \\, \\cdots{} $\n",
    "##### $ \\hspace{0.15cm} $ ② 분류(classification) : cross entropy, hinge loss, $ \\, \\cdots{} $ \n",
    "##### $ \\hspace{0.45cm} \\vdots{} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 그 외에도 강화학습, 오토인코더, 객체탐지등의 문제 상황에 맞는 손실 함수가 존재함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **평균 절대 오차(Mean Absolute Error;MAE;L1 Loss)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 잔차(Residual)를 절댓값으로 처리하여 측정하는 회귀 지표\n",
    "#### $ \\Rightarrow{} \\ell{}^{(i)} = |y^{(i)}-\\hat{y}^{(i)}| $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 엄밀한 의미로 실제 데이터에 모델을 적합한 후, 각 관측치에 대해 계산되는 오차 $ = $ 잔차이나, 단순히 에러(오차;error)라고 범용적으로 표현함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : \n",
    "##### $ \\hspace{0.15cm} $ ① 오차의 크기에 선형적으로 비례\n",
    "##### $ \\hspace{0.15cm} $ ② 오차가 라플라스 분포를 가정할 때 최대우도추정(Maximum Likelihood Estimatation)로 도출됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`) 라플라스 분포(laplace distribution)** : 정규 분포와 흡사하게 생겼지만, 둥근 종 모양이 아니라 뾰족한 산맥처럼 생긴 분포\n",
    "##### $ \\hspace{0.15cm} \\Rightarrow{} f_{X}(x) = \\frac{1}{2b} e^{-\\frac{|x-\\mu{}|}{b}} \\;\\; \\text{ where } \\, b \\, \\text{ is scale parameter}.  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $ \\hspace{0.15cm} $ ③ 큰 오차에 민감하지 않음 $ = $ 이상치에 덜 민감함(robust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① (MSE에 비해) 해석이 직관적임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 절댓값 함수 특성상 미분 불연속점 존재해 최적화 속도가 느릴 수 있음\n",
    "##### $ \\hspace{0.15cm} $ ② 최적화 시 그래디언트(gradient)의 부드러움이 떨어질 수 있음을 언급"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **평균 제곱 오차(Mean Squared Error;MSE;L2 Loss)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 잔차를 제곱하여 측정한 회귀 지표\n",
    "#### $ \\Rightarrow{} \\ell{}^{(i)} = (y^{(i)}-\\hat{y}^{(i)})^{2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : \n",
    "##### $ \\hspace{0.15cm} $ ① 오차의 크기가 클수록 더 큰 페널티를 부여(비선형적 증가)\n",
    "##### $ \\hspace{0.15cm} $ ② 오차가 정규분포(normal distribution)을 가정할 때 최대우도추정으로 도출됨\n",
    "##### $ \\hspace{0.15cm} $ ③ 큰 오차에 민감함 $ = $ 이상치에 민감함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① (모든 지점에서) 미분 가능해 최적화에 용이함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① (MAE에 비해) 해석이 직관적이지 않을 수 있음\n",
    "##### $ \\hspace{0.15cm} $ ② 큰 오차에 대해 강한 패널티를 주기 때문에 그래디언트 폭발(exploding gradient) 발생 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`WHY?`)** MAE는 오차의 단위가 원 데이터 단위와 동일하지만, MSE는 오차의 제곱값으로 표현되기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **크로스 엔트로피(Cross Entropy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 정답 클래스와 예측 클래스 간의 차이(불일치 정도)를 확률로 측정하는 분류 지표\n",
    "#### $ \\Rightarrow{} \\ell{}^{(i)} = - \\displaystyle\\sum^{n_{y}}_{k=1} y^{(i)}_{k} \\log{}\\hat{y}^{(i)}_{k} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : 두 확률분포 간의 차이를 엔트로피로 측정, 예측의 불확실성이 높을수록 손실 값이 커짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`) 정보(Information)와 엔트로피(Entropy)** : \n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 정보 : (정보이론에서) 어떠한 사건 $ \\, A $ 의 **발생 빈도가 얼마나 드문지**를 정량적으로 나타낸 지표\n",
    "##### $ \\hspace{0.3cm} \\Rightarrow{} I(x) = - \\log{}P(A) = - \\log{}P(x) \\;\\; \\text{ where } \\, P(x) \\, \\text{ is probability of event } \\, A. $\n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 엔트로피 : 확률분포 $ \\, P(x) $ 에 대해 각 사건의 정보량에 해당 사건이 발생할 확률을 가중치로 하여 평균을 낸 값\n",
    "##### $ \\hspace{0.3cm} \\Rightarrow{} H(x) = - \\displaystyle\\sum_{x} P(x)\\log{}P(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① 그래디언트가 명확해 최적화가 용이함\n",
    "##### $ \\hspace{0.15cm} $ ② 확률적 해석 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 모델이 극단적인 확률(예: $ \\, 0.9999 $ vs $ \\, 0.0001 $)을 예측할 때 손실이 매우 커지는 문제(over-shooting) 발생 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 통계학적 관점의 크로스 엔트로피(cross entopy) : \n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 크로스 엔트로피는 확률 분포 $ \\, p(x) $ 에서 뽑힌 정답 데이터를, $ \\, q(x) $ 를 모델로 표현할 때 필요한 평균 정보량을 측정함 (두 분포가 가까울수록 값이 작아짐)\n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\,\\, i $ 번 째 정답 벡터($ \\textbf{y}^{(i)} $)는 **실현화된** 확률 분포이며, 예측 벡터($ \\hat{\\textbf{y}}^{(i)} $) 역시 확률 변환 활성화함수(ex. 시그모이드, 소프트맥스)를 취하면 확률 분포가 됨 \n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} H(p, q) = - \\displaystyle\\sum_{x} p(x) \\log{} q(x) = - \\displaystyle\\sum^{n_{y}}_{k=1} y^{(i)}_{k} \\log{}\\hat{y}^{(i)}_{k} $\n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 최대우도추정의 관점에서는 우도(likelihood;$ L(\\theta{}|x) $) 함수에 로그를 취하고 음수를 곱한 것이 크로스 엔트로피의 형태임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 크로스 엔트로피와 KL 발산(Kullback-Leibler divergence)의 관계 : \n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\,\\, D_{KL}(p|q) = \\displaystyle\\sum_{x}p(x)\\log{}(\\frac{p(x)}{q(x)}) \\, $ : 두 확률 분포 $ \\, p(x),\\, q(x) $ 의 확률적 차이를 측정한 지표\n",
    "##### $ \\hspace{0.15cm} \\cdot{} \\, $ 크로스 엔트로피는 $ \\, p(x) $ 가 원핫벡터(분포)임을 가정할 때 KL 발산과 엔트로피로 분해됨\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} H(p,q) = D_{KL}(p|q) + H(p) = D_{KL}(p|q) - \\displaystyle\\sum_{x} p(x)\\log{}p(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **힌지 손실(Hinge Loss)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 마진(margin)을 이용하여 정답 클래스와 나머지 클래스 간 점수(score)의 차이를 측정하는 분류지표\n",
    "#### $ \\Rightarrow{} \\ell{}^{(i)} = \\displaystyle\\sum_{j\\neq{}y^{(i)}_{*}} \\max{}(0, z^{(i)}_{j} - z^{(i)}_{y^{(i)}_{*}}+\\Delta{}) \\;\\; \\text{ where } \\, \\Delta{} \\, \\text{ is margin}. $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : 올바른 클래스의 점수(선형결합값)가 다른 클래스의 점수보다 최소한 마진만큼 높도록 설정함\n",
    "#### $ = $ 모델이 올바른 클래스를 충분히 높게 예측(마진 조건을 만족)하면 비 업데이트, 그렇지 않을 때만 손실을 발생시켜 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① 명확한 마진을 고려하기 때문에 클래스 간의 구분을 뚜렷하게 만들어 일반화 성능 향상\n",
    "##### $ \\hspace{0.15cm} $ ② 이상치에 덜 민감함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① (크로스 엔트로피에 비해) 확률적 해석이 어려움\n",
    "##### $ \\hspace{0.15cm} $ ② 미분값(gradient)이 일부 구간에서 사라지거나 불연속일 수 있어 최적화가 어려움"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
