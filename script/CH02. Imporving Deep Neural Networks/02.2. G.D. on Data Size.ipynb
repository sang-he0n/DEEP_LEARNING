{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH02.2. **Gradient Descent on Data Size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Gradient Descent on Data Size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 종류** : \n",
    "##### $ \\hspace{0.15cm} $ ① Batch Gradient Descent\n",
    "##### $ \\hspace{0.15cm} $ ② Minibatch Gradient Descent\n",
    "##### $ \\hspace{0.15cm} $ ③ Stochastic Gradient Descent(SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Batch(Epoch) Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 전체 데이터셋을 사용하여 비용 함수의 그래디언트를 계산하고, 이를 기반으로 파라미터를 한 번 업데이트하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① 정확한 그래디언트 계산\n",
    "##### $ \\hspace{0.15cm} $ ② 안정적인 수렴 \n",
    "##### $ \\hspace{0.15cm} $ ③ 재현성 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 메모리 부담 높음\n",
    "##### $ \\hspace{0.15cm} $ ② 느린 파라미터 업데이트 속도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Minibatch Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 전체 데이터셋을 작은 배치로 분할하여 각 배치마다 그래디언트를 계산하고 파라미터를 업데이트하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① 계산 효율성 향상 : 배치 단위로 벡터화된 연산이 가능하여 CPU/GPU를 효율적으로 활용\n",
    "##### $ \\hspace{0.15cm} $ ② (SGD에 비해) 변동성 감소\n",
    "##### $ \\hspace{0.15cm} $ ③ 유연성 : 배치 크기를 조절하여 Batch Gradient Descent와 SGD의 장점을 조합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 하이퍼파라미터(미니배치 크기) 튜닝 필요\n",
    "##### $ \\hspace{0.15cm} $ ② 복잡성 증가: 배치 처리에 따른 추가적인 코드 구현이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Stochastic Gradient Descent(SGD)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 각 데이터 포인트마다 비용 함수의 그래디언트를 계산하고 파라미터를 업데이트하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 장점** : \n",
    "##### $ \\hspace{0.15cm} $ ① 빠른 학습속도\n",
    "##### $ \\hspace{0.15cm} $ ② 낮은 메모리 사용량\n",
    "##### $ \\hspace{0.15cm} $ ③ 전역 최적화 가능성 : 그래디언트의 노이즈로 인해 지역 최소값에서 벗어나 전역 최소값을 탐색할 가능성 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 단점** :\n",
    "##### $ \\hspace{0.15cm} $ ① 업데이트 시 노이즈가 많아 최적해 근처에서 진동하기 떄문에 변동성 높음\n",
    "##### $ \\hspace{0.15cm} $ ② 수렴 속도 느림 : 최적해 근처에서 진동하여 정확한 수렴이 어려울 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
