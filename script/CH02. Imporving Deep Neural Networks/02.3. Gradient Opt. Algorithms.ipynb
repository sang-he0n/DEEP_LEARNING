{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH02.3. **Gradient Optimization Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Gradient Optimization Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 확률적 경사하강법(SGD)에서 발생하는 노이즈 문제를 보완하기 위해 고안된 경사하강법 최적화 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **(`PLUS`)** 배치 경사하강법의 경우 그라디언트의 노이즈가 상대적으로 작아, 최적화 방법을 사용할 필요성이 적음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 종류** : \n",
    "##### $ \\hspace{0.15cm} $ ① 모멘텀(Momentum)\n",
    "##### $ \\hspace{0.15cm} $ ② 네스테로프 가속 경사(Nesterov Acclearted Gradient)\n",
    "##### $ \\hspace{0.15cm} $ ③ 적응형 경사법(AdaGrad;Adaptive Gradient)\n",
    "##### $ \\hspace{0.15cm} $ ④ Root Mean Square Propagation(RMSProp)\n",
    "##### $ \\hspace{0.15cm} $ ⑤ 아담(Adaptive Moment Estimation;Adam)\n",
    "##### $ \\hspace{0.15cm} $ ⑥ 가중치감쇠 아담(Adam with Weight Decay;AdamW)\n",
    "##### $ \\hspace{0.15cm} $ ⑦ 학습률 감쇠(Learning Rate Decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **모멘텀(Momentum)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 기울기의 **1차 모멘트**(과거 기울기의 지수 가중 평균)를 이용하여 일관된 방향으로의 이동을 촉진하는 방법\n",
    "##### $ \\hspace{0.15cm} $ ① Forward propagation\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} \\theta{}^{[l]}_{t} = \\theta{}^{[l]}_{t-1} - \\alpha{} \\cdot{} v^{[l]}_{t} \\;\\; \\text{ where } \\, v^{[l]}_{t} = \\beta{}_{1} \\cdot{} v^{[l]}_{t-1} + (1 - \\beta{}_{1} ) \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}} $\n",
    "##### $ \\hspace{0.15cm} $ ② Back propagation\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} $ **[LATEX]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : \n",
    "##### $ \\hspace{0.15cm} $ ① 과거 기울기의 정보를 누적하여 현재 업데이트에 반영함으로써, 노이즈를 줄이고 부드럽게 업데이트\n",
    "##### $ \\hspace{0.15cm} $ ② 관성 효과를 통해 급격한 기울기 변화에도 일관된 방향성을 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **네스테로프 가속 경사(Nesterov Acclearted Gradient)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **적응형 경사법(AdaGrad;Adaptive Gradient)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Root Mean Square Propagation(RMSProp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 기울기의 **2차 모멘트**(모멘트의 제곱)를 이용하여 그라디언트에 따라 학습률(learning rate)을 조정하는 방법\n",
    "##### $ \\hspace{0.15cm} $ ① Forward propagation\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} \\theta{}^{[l]}_{t} = \\theta{}^{[l]}_{t-1} - \\alpha{} \\cdot{} \\frac{1}{\\sqrt{s^{[l]}_{t}+\\epsilon{}}} \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}} \\;\\; \\text{ where } \\, s^{[l]}_{t} = \\beta{}_{2} \\cdot{} s^{[l]}_{t-1} + (1 - \\beta{}_{2} ) \\cdot{} (\\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}})^{2} $\n",
    "##### $ \\hspace{5.65cm} \\text{and } \\, \\epsilon{} \\approx{} 10^{-7} $ \n",
    "##### $ \\hspace{0.15cm} $ ② Back propagation\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} $ **[LATEX]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : \n",
    "##### $ \\hspace{0.15cm} $ ① 학습률을 자동으로 조정하여 기울기가 큰 파라미터는 학습률을 작게 조정(반대 경우도 작동)\n",
    "##### $ \\hspace{0.15cm} $ ② 학습 과정의 노이즈를 줄이고 학습이 불안정한 문제에 대해 보다 안정적인 업데이트를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **아담(Adaptive Moment Estimation;Adam)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : Momentum과 RMSProp을 모두 이용하여 그라디언트의 일관성과 학습률을 조정하는 방법\n",
    "##### $ \\hspace{0.15cm} $ ① Forward propagation\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} \\theta{}^{[l]}_{t} = \\theta{}^{[l]}_{t-1} - \\alpha{} \\cdot{} \\frac{1}{\\sqrt{s^{[l]}_{t}+\\epsilon{}}} \\cdot{} v^{[l]}_{t} \\;\\; \\text{ where } \\, v^{[l]}_{t} = \\beta{}_{1} \\cdot{} v^{[l]}_{t-1} + (1 - \\beta{}_{1} ) \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}} $ \n",
    "##### $ \\hspace{5.275cm} \\text{and } \\, s^{[l]}_{t} = \\beta{}_{2} \\cdot{} s^{[l]}_{t-1} + (1 - \\beta{}_{2} ) \\cdot{} (\\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}})^{2} $\n",
    "##### $ \\hspace{0.15cm} $ ② Back propagation\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} $ **[LATEX]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 특징** : \n",
    "##### $ \\hspace{0.15cm} $ ① Momentum 성분을 사용하여 이전 기울기의 정보를 누적, 급격한 진동 없이 일관된 방향으로 빠르게 수렴\n",
    "##### $ \\hspace{0.15cm} $ ② RMSProp 성분을 통해 각 파라미터의 기울기 크기에 따라 학습률을 자동으로 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **가중치감쇠 아담(Adam with Weight Decay;AdamW)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **학습률 감쇠(Learning Rate Decay)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 학습 초반에는 큰 보폭으로 빠르게 학습하다가 후반에는 작은 보폭으로 학습률을 점진적으로 줄여 최적화하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 종류** : \n",
    "##### $ \\hspace{0.15cm} $ ① 지수 감쇠(Exponential Decay)\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} \\alpha{}_{t} = \\alpha{}_{0} \\times{} e^{-kt} \\;\\; \\text{ where } k : \\text{decay rate} $\n",
    "##### $ \\hspace{0.15cm} $ ② 시간 기반 감쇠(Time-based Decay)\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} \\alpha{}_{t} = \\alpha{}_{0} \\times{} \\frac{1}{1+kt} $\n",
    "##### $ \\hspace{0.15cm} $ ③ 단계별 감쇠(Step Decay)\n",
    "##### $ \\hspace{0.45cm} \\Rightarrow{} \\alpha{}_{t} = \\alpha{}_{0} \\times{} \\beta{}^{[\\frac{t}{\\text{epoch\\_drop}}]} \\;\\; \\text{ where } \\, \\beta{} : \\text{decay factor}, \\;\\; \\text{epoch\\_drop} : \\text{drop interval} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 특징** : \n",
    "##### $ \\hspace{0.15cm} $ ① 초기에는 큰 학습률로 빠른 수렴을 도모\n",
    "##### $ \\hspace{0.15cm} $ ② 후반에는 작은 학습률로 오버슈팅이나 진동을 줄여 더 안정적인 수렴을 지원"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
